{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pylupnt as pnt\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pylupnt.features import SuperPoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import main_pnp_vo\n",
    "\n",
    "output_dir = main_pnp_vo.output_dir\n",
    "figures_dir = output_dir / \"figures\"\n",
    "os.makedirs(figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs and poses from output directory\n",
    "output_path = sorted(glob.glob(str(output_dir / \"main_pnp_vo_results_*.pkl\")))[-1]\n",
    "with open(output_path, \"rb\") as f:\n",
    "    output = pickle.load(f)\n",
    "pnt.Logger.info(f\"Loaded {len(output['runs'])} runs from {output_path}\", \"Main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_poses_tmp = output[\"gt_poses\"]\n",
    "bTw0 = pnt.invert_transform(gt_poses_tmp[0])\n",
    "gt_poses = np.array([bTw0 @ pose for pose in gt_poses_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pnt.datasets.Dataset.from_config(output[\"ds_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractors = {\n",
    "    k: pnt.FeatureExtractor.from_config(v)\n",
    "    for k, v in main_pnp_vo.extractor_configs.items()\n",
    "}\n",
    "matchers = {\n",
    "    k: pnt.FeatureMatcher.from_config(v) for k, v in main_pnp_vo.matcher_configs.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 180\n",
    "m = int(np.ceil(len(extractors) / 2))\n",
    "fig, axs = plt.subplots(2, m, figsize=(10, 5))\n",
    "\n",
    "plt.sca(axs.flat[0])\n",
    "plt.imshow(dataset[idx][\"cameras\"][\"front_left\"][\"rgb\"])\n",
    "plt.title(\"RGB\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "img_extractors = [\"ORB\", \"AKAZE\", \"BRISK\", \"SIFT\", \"SuperPoint\"]\n",
    "\n",
    "for i, extractor_name in enumerate(img_extractors):\n",
    "    img_data = dataset[idx][\"cameras\"][\"front_left\"]\n",
    "    feats = extractors[extractor_name].extract(img_data.rgb)\n",
    "    plt.sca(axs.flat[i + 1])\n",
    "    plt.imshow(img_data.rgb)\n",
    "    plt.title(extractor_name)\n",
    "    plt.scatter(feats.uv[:, 0], feats.uv[:, 1], color=\"cyan\", s=1, zorder=10)\n",
    "    plt.axis(\"off\")\n",
    "    plt.text(\n",
    "        0.98,\n",
    "        0.98,\n",
    "        f\"{len(feats)} features\",\n",
    "        color=\"white\",\n",
    "        fontsize=10,\n",
    "        va=\"top\",\n",
    "        ha=\"right\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        bbox=dict(\n",
    "            facecolor=\"black\", alpha=0.4, edgecolor=\"none\", boxstyle=\"round,pad=0.2\"\n",
    "        ),\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / \"feature_extraction_all.pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "img_extractors = [\"ORB\", \"AKAZE\", \"BRISK\", \"SIFT\", \"SuperPoint\"]\n",
    "\n",
    "times = {}\n",
    "\n",
    "for i, extractor_name in tqdm(enumerate(img_extractors), total=len(img_extractors)):\n",
    "    feats = extractors[extractor_name].extract(img_data.rgb)\n",
    "    times_tmp = []\n",
    "    for i in range(100):\n",
    "        rgb = dataset[i][\"cameras\"][\"front_left\"][\"rgb\"]\n",
    "        ts = time.time()\n",
    "        feats = extractors[extractor_name].extract(rgb)\n",
    "        te = time.time()\n",
    "        times_tmp.append(te - ts)\n",
    "    times[extractor_name] = times_tmp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Calculate mean and std for each extractor\n",
    "means = []\n",
    "stds = []\n",
    "for ex in img_extractors:\n",
    "    arr = np.array(times[ex])\n",
    "    means.append(np.mean(arr * 1000.0))  # ms\n",
    "    stds.append(np.std(arr * 1000.0))  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3), dpi=300)\n",
    "x = np.arange(len(img_extractors))\n",
    "plt.bar(x, means, yerr=stds, color=\"C0\", alpha=0.7, capsize=4)\n",
    "plt.xticks(x, img_extractors)\n",
    "plt.ylabel(\"Time per image [ms]\")\n",
    "plt.title(\"Feature extraction time (100 iterations)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / \"feature_extraction_bench.pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "img_combinations = [\n",
    "    (\"ORB\", \"BruteForce\"),\n",
    "    (\"AKAZE\", \"Flann\"),\n",
    "    (\"BRISK\", \"Flann\"),\n",
    "    (\"SIFT\", \"LightGlue\"),\n",
    "    (\"SuperPoint\", \"SuperGlue\"),\n",
    "    (\"SuperPoint\", \"LightGlue\"),\n",
    "]\n",
    "\n",
    "idx = 180\n",
    "img_data1 = dataset[idx][\"cameras\"][\"front_left\"]\n",
    "img_data2 = dataset[idx + 1][\"cameras\"][\"front_left\"]\n",
    "\n",
    "\n",
    "h, w = img_data1[\"rgb\"].shape[:2]\n",
    "ws = 10\n",
    "sep = np.ones((h, ws, 3))\n",
    "\n",
    "res_dict = {}\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(6, 4), dpi=300)\n",
    "for i, (e_name, m_name) in tqdm(\n",
    "    enumerate(img_combinations), total=len(img_combinations)\n",
    "):\n",
    "    e_cfg = main_pnp_vo.extractor_configs[e_name]\n",
    "    m_cfg = main_pnp_vo.matcher_configs[m_name]\n",
    "    e_cfg_tmp, m_cfg_tmp = main_pnp_vo.process_config(e_name, e_cfg, m_name, m_cfg)\n",
    "    if e_cfg_tmp is None or m_cfg_tmp is None:\n",
    "        continue\n",
    "    extractor = pnt.FeatureExtractor.from_config(e_cfg_tmp)\n",
    "    matcher = pnt.FeatureMatcher.from_config(m_cfg_tmp)\n",
    "\n",
    "    feats1 = extractor.extract(img_data1.rgb)\n",
    "    feats2 = extractor.extract(img_data2.rgb)\n",
    "    matches = matcher.match(feats1, feats2)\n",
    "\n",
    "    # Check valid feature coordinates in image 1\n",
    "    u1 = feats1.uv[:, 0].astype(np.int32).clip(0, w - 1)\n",
    "    v1 = feats1.uv[:, 1].astype(np.int32).clip(0, h - 1)\n",
    "\n",
    "    depth1 = img_data1.depth[v1, u1]\n",
    "\n",
    "    # Convert to 3D world coordinates\n",
    "    xyz_c1 = pnt.uv_to_xyz(feats1.uv, depth1, img_data1.intrinsics)\n",
    "    xyz1_w = pnt.apply_transform(img_data1.world_T_cam, xyz_c1)\n",
    "\n",
    "    # Project to image 2\n",
    "    uv2_true, depth2 = pnt.xyz_to_uv(\n",
    "        xyz1_w, img_data2.intrinsics, img_data2.world_T_cam, return_depth=True\n",
    "    )\n",
    "\n",
    "    # Filter valid projections\n",
    "    valid_mask2: np.ndarray = (\n",
    "        (depth1 > 0)\n",
    "        & (depth2 > 0)\n",
    "        & (0 <= uv2_true[:, 0])\n",
    "        & (uv2_true[:, 0] < w)\n",
    "        & (0 <= uv2_true[:, 1])\n",
    "        & (uv2_true[:, 1] < h)\n",
    "    )\n",
    "\n",
    "    # Match distance\n",
    "    gt_thresh = 0.01 * w\n",
    "    dist_match = np.linalg.norm(\n",
    "        uv2_true[matches.indexes[:, 0]] - feats2.uv[matches.indexes[:, 1]], axis=1\n",
    "    )\n",
    "    dists_normed = np.clip(dist_match / gt_thresh / 2.0, 0, 1)\n",
    "    dists_normed = np.where(np.isnan(dists_normed), 1.0, dists_normed)\n",
    "    match_colors = np.vstack(\n",
    "        [dists_normed, 1 - dists_normed, np.zeros(len(dists_normed))]\n",
    "    ).T\n",
    "\n",
    "    # Precision and recall\n",
    "    matched = np.zeros(len(feats1), dtype=np.bool)\n",
    "    matched[matches.indexes[:, 0]] = True\n",
    "    dist_feats1 = np.full(len(feats1), np.nan)\n",
    "    dist_feats1[matches.indexes[:, 0]] = dist_match\n",
    "    pos = (dist_feats1 < gt_thresh) & valid_mask2\n",
    "    neg = (dist_feats1 >= gt_thresh) | ~valid_mask2\n",
    "    tp = matched & pos\n",
    "    fp = matched & neg\n",
    "    fn = ~matched & pos\n",
    "    prec = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    rec = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "\n",
    "    print(f\"Positive: {np.sum(pos)}, Negative: {np.sum(neg)}\")\n",
    "    print(f\"TP: {np.sum(tp)}, FP: {np.sum(fp)}, FN: {np.sum(fn)}\")\n",
    "    print(f\"Precision: {prec:.2f}, Recall: {rec:.2f}\")\n",
    "\n",
    "    res_dict[f\"{e_name} + {m_name}\"] = {\n",
    "        \"name\": f\"{e_name} + {m_name}\",\n",
    "        \"n_left\": len(feats1),\n",
    "        \"n_right\": len(feats2),\n",
    "        \"n_matches\": len(matches),\n",
    "        \"tp\": np.sum(tp),\n",
    "        \"fp\": np.sum(fp),\n",
    "        \"fn\": np.sum(fn),\n",
    "        \"prec\": prec,\n",
    "        \"rec\": rec,\n",
    "    }\n",
    "\n",
    "    plt.sca(axs.flat[i])\n",
    "    idxs = np.random.choice(len(matches), size=min(100, len(matches)), replace=False)\n",
    "    plt.imshow(np.hstack((img_data1.rgb, sep, img_data2.rgb)))\n",
    "    for j in idxs:\n",
    "        i1 = matches.indexes[j, 0]\n",
    "        i2 = matches.indexes[j, 1]\n",
    "        pt1 = feats1.uv[i1]\n",
    "        pt2 = feats2.uv[i2]\n",
    "        plt.plot(\n",
    "            [pt1[0], pt2[0] + w + ws],\n",
    "            [pt1[1], pt2[1]],\n",
    "            color=match_colors[j],\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"{e_name} + {m_name}\")\n",
    "    plt.xlim(0, 2 * w + ws)\n",
    "    plt.ylim(h, 0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / \"feature_matching_all.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Update table after each entry (move after loop for efficiency if needed)\n",
    "res_table = pd.DataFrame(res_dict.values())\n",
    "res_table[\"prec\"] = res_table[\"prec\"].map(\"{:.2f}\".format)\n",
    "res_table[\"rec\"] = res_table[\"rec\"].map(\"{:.2f}\".format)\n",
    "\n",
    "res_table[[\"name\", \"n_left\", \"n_right\", \"n_matches\", \"prec\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5), dpi=400)\n",
    "\n",
    "gt_x = gt_poses[:, 0, 3]\n",
    "gt_y = gt_poses[:, 1, 3]\n",
    "plt.plot(gt_x, gt_y, label=\"Ground truth\", color=\"black\", linestyle=\"--\")\n",
    "plt.scatter(gt_x[-1], gt_y[-1], s=20, label=\"Final position\", color=\"black\")\n",
    "\n",
    "failed = []\n",
    "for run in output[\"runs\"][:]:\n",
    "    poses = run[\"poses\"]\n",
    "    e_name = run[\"extractor\"]\n",
    "    m_name = run[\"matcher\"]\n",
    "    label = f\"{e_name} + {m_name}\"\n",
    "    if len(poses) > 1:\n",
    "        xy = poses[:, :2, 3]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], label=label)\n",
    "        plt.scatter(xy[-1, 0], xy[-1, 1], s=20)\n",
    "    else:\n",
    "        failed.append(label)\n",
    "\n",
    "for label in failed:\n",
    "    plt.scatter([], [], label=label, facecolor=\"none\", edgecolor=\"none\")\n",
    "\n",
    "plt.xlabel(\"X [m]\")\n",
    "plt.ylabel(\"Y [m]\")\n",
    "plt.legend(fontsize=8, loc=\"upper left\", ncol=2)\n",
    "plt.axis(\"equal\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_name = \"front_left\"\n",
    "\n",
    "metrics_results = {}\n",
    "for run in output[\"runs\"]:\n",
    "    run_name = run[\"extractor\"] + \" + \" + run[\"matcher\"]\n",
    "    result = {\n",
    "        \"num_matches\": [],\n",
    "        \"prec\": [],\n",
    "        \"rec\": [],\n",
    "        \"ea_t\": [],\n",
    "        \"er_t\": [],\n",
    "        \"ea_R\": [],\n",
    "        \"er_R\": [],\n",
    "    }\n",
    "\n",
    "    n_frames = len(run[\"poses\"])\n",
    "    for t in tqdm(range(1, n_frames), desc=f\"{run['extractor']} + {run['matcher']}\"):\n",
    "        # Features and matches\n",
    "        feats1: pnt.Features = run[\"features\"][t - 1]\n",
    "        feats2: pnt.Features = run[\"features\"][t]\n",
    "        matches: pnt.Matches = run[\"matches\"][t]\n",
    "\n",
    "        # Images\n",
    "        img_data1: pnt.ImageData = dataset[t - 1][\"cameras\"][cam_name]\n",
    "        img_data2: pnt.ImageData = dataset[t][\"cameras\"][cam_name]\n",
    "\n",
    "        # Poses\n",
    "        wTc1 = run[\"poses\"][t - 1]\n",
    "        wTc2 = run[\"poses\"][t]\n",
    "        wTc1_gt = gt_poses[t - 1]\n",
    "        wTc2_gt = gt_poses[t]\n",
    "\n",
    "        # Compute error\n",
    "        c2Tc1 = pnt.invert_transform(wTc2) @ wTc1\n",
    "        c2Tc1_gt = pnt.invert_transform(wTc2_gt) @ wTc1_gt\n",
    "        ea_t = np.linalg.norm(c2Tc1_gt[:3, 3] - c2Tc1[:3, 3])\n",
    "        er_t = ea_t / np.linalg.norm(c2Tc1_gt[:3, 3])\n",
    "        ea_R = pnt.rotation_angle(c2Tc1[:3, :3] @ c2Tc1_gt[:3, :3].T) * pnt.DEG\n",
    "        er_R = ea_R / pnt.rotation_angle(c2Tc1_gt[:3, :3]) / pnt.DEG\n",
    "\n",
    "        # Convert to 3D world coordinates\n",
    "        h, w = img_data1.rgb.shape[:2]\n",
    "        u1 = feats1.uv[:, 0].astype(np.int32).clip(0, w - 1)\n",
    "        v1 = feats1.uv[:, 1].astype(np.int32).clip(0, h - 1)\n",
    "        depth1 = img_data1.depth[v1, u1]\n",
    "        xyz_c1 = pnt.uv_to_xyz(feats1.uv, depth1, img_data1.intrinsics)\n",
    "        xyz1_w = pnt.apply_transform(img_data1.world_T_cam, xyz_c1)\n",
    "\n",
    "        # Project to image 2\n",
    "        uv2_true, depth2 = pnt.xyz_to_uv(\n",
    "            xyz1_w, img_data2.intrinsics, img_data2.world_T_cam, return_depth=True\n",
    "        )\n",
    "\n",
    "        # Filter valid projections\n",
    "        valid_mask2: np.ndarray = (\n",
    "            (depth1 > 0)\n",
    "            & (depth2 > 0)\n",
    "            & (0 <= uv2_true[:, 0])\n",
    "            & (uv2_true[:, 0] < w)\n",
    "            & (0 <= uv2_true[:, 1])\n",
    "            & (uv2_true[:, 1] < h)\n",
    "        )\n",
    "\n",
    "        # Compute pairwise distances between uv2_true and feats2.uv\n",
    "        all_dists = np.linalg.norm(uv2_true[:, None, :] - feats2.uv[None, :, :], axis=2)\n",
    "        dist_true2feats = np.min(all_dists, axis=1)\n",
    "        dist_feats2true = np.min(all_dists, axis=0)\n",
    "\n",
    "        # Match distance\n",
    "        gt_thresh = 0.01 * w\n",
    "        dist_match = np.linalg.norm(\n",
    "            uv2_true[matches.indexes[:, 0]] - feats2.uv[matches.indexes[:, 1]], axis=1\n",
    "        )\n",
    "        dists_normed = np.clip(dist_match / gt_thresh / 2.0, 0, 1)\n",
    "        dists_normed = np.where(np.isnan(dists_normed), 1.0, dists_normed)\n",
    "        match_colors = np.vstack(\n",
    "            [dists_normed, 1 - dists_normed, np.zeros(len(dists_normed))]\n",
    "        ).T\n",
    "\n",
    "        # Precision and recall\n",
    "        matched = np.zeros(len(feats1), dtype=np.bool)\n",
    "        matched[matches.indexes[:, 0]] = True\n",
    "        dist_feats1 = np.full(len(feats1), np.nan)\n",
    "        dist_feats1[matches.indexes[:, 0]] = dist_match\n",
    "        pos = (dist_feats1 < gt_thresh) & valid_mask2\n",
    "        neg = (dist_feats1 >= gt_thresh) | ~valid_mask2\n",
    "        tp = matched & pos\n",
    "        fp = matched & neg\n",
    "        fn = ~matched & pos\n",
    "        prec = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "        rec = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "\n",
    "        # Add results\n",
    "        result[\"num_matches\"].append(len(matches))\n",
    "        result[\"prec\"].append(prec)\n",
    "        result[\"rec\"].append(rec)\n",
    "        result[\"ea_t\"].append(ea_t)\n",
    "        result[\"er_t\"].append(er_t)\n",
    "        result[\"ea_R\"].append(ea_R)\n",
    "        result[\"er_R\"].append(er_R)\n",
    "\n",
    "    result = {k: np.array(v) for k, v in result.items()}\n",
    "    metrics_results[run_name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = metrics_results[\"SuperPoint + LightGlue\"]\n",
    "run = [\n",
    "    run\n",
    "    for run in output[\"runs\"]\n",
    "    if run[\"extractor\"] + \" + \" + run[\"matcher\"] == \"SuperPoint + LightGlue\"\n",
    "][0]\n",
    "\n",
    "text_kwargs = dict(\n",
    "    fontsize=10,\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5, edgecolor=\"none\", boxstyle=\"round,pad=0.2\"),\n",
    ")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 2.5), dpi=300)\n",
    "\n",
    "plt.sca(axs[0])\n",
    "plt.plot(result[\"ea_t\"])\n",
    "plt.xlim(0, len(result[\"ea_t\"]))\n",
    "plt.ylabel(\"Translation\\n Error [m]\")\n",
    "text = f\"Min: {np.min(result['ea_t']):.2f} m    \"\n",
    "text += f\"Max: {np.max(result['ea_t']):.2f} m\\n\"\n",
    "text += f\"Mean: {np.mean(result['ea_t']):.2f} m  \"\n",
    "text += f\"Std: {np.std(result['ea_t']):.2f} m\"\n",
    "plt.text(0.5, 0.95, text, **text_kwargs, transform=plt.gca().transAxes)\n",
    "plt.ylim(0, 0.2)\n",
    "plt.grid()\n",
    "\n",
    "plt.sca(axs[1])\n",
    "plt.plot(result[\"ea_R\"])\n",
    "plt.xlim(0, len(result[\"er_t\"]))\n",
    "plt.ylabel(\"Rotation\\n Error [deg]\")\n",
    "text = f\"Min: {np.min(result['er_t']):.2f}$^\\\\circ$   \"\n",
    "text += f\"Max: {np.max(result['er_t']):.2f}$^\\\\circ$\\n\"\n",
    "text += f\"Mean: {np.mean(result['er_t']):.2f}$^\\\\circ$ \"\n",
    "text += f\"Std: {np.std(result['er_t']):.2f}$^\\\\circ$\"\n",
    "plt.text(0.5, 0.95, text, **text_kwargs, transform=plt.gca().transAxes)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2), dpi=400)\n",
    "\n",
    "gt_x = gt_poses[:, 0, 3]\n",
    "gt_y = gt_poses[:, 1, 3]\n",
    "plt.plot(gt_x, gt_y, label=\"Ground truth\", color=\"black\", linestyle=\"--\")\n",
    "plt.scatter(gt_x[-1], gt_y[-1], s=20, label=\"Final position\", color=\"black\")\n",
    "\n",
    "xy = run[\"poses\"][:, :2, 3]\n",
    "\n",
    "pnt.plot_colored_line_by_value(\n",
    "    xy[:, 0],\n",
    "    xy[:, 1],\n",
    "    result[\"er_t\"],\n",
    "    cmap=\"GnYlRd\",\n",
    "    vmax=0.1,\n",
    "    cbar_label=\"Translation Error [m]\",\n",
    ")\n",
    "plt.xlabel(\"X [m]\")\n",
    "plt.ylabel(\"Y [m]\")\n",
    "plt.legend(fontsize=8, loc=\"upper left\")\n",
    "plt.axis(\"equal\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = [\n",
    "    run\n",
    "    for run in output[\"runs\"]\n",
    "    if run[\"extractor\"] + \" + \" + run[\"matcher\"] == \"SuperPoint + LightGlue\"\n",
    "][0]\n",
    "result = metrics_results[\"SuperPoint + LightGlue\"]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10, 3), dpi=400)\n",
    "for i in range(4):\n",
    "    plt.sca(axs[i])\n",
    "    plt.imshow(dataset[i + 15][\"cameras\"][\"front_left\"][\"rgb\"])\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_config = pnt.load_config(\n",
    "    {\n",
    "        \"inherit_from\": \"unreal.yaml\",\n",
    "        \"basedir\": \"/home/shared_ws6/local_traverse/base_1\",\n",
    "        \"preload\": \"none\",\n",
    "        \"data_types\": [\"rgb\"],\n",
    "        \"cameras\": [\"front_left\", \"left_left\", \"right_left\", \"back_left\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "ds = pnt.datasets.UnrealDataset(ds_config)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Put cameras in canonical left-front-right-back order if present\n",
    "wanted_order = [\"left_left\", \"front_left\", \"right_left\", \"back_left\"]\n",
    "cameras = [cam for cam in wanted_order if cam in ds_config[\"cameras\"]]\n",
    "\n",
    "# Prepare figure: 1 row, 4 columns\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3), constrained_layout=True)\n",
    "\n",
    "n_frames = len(ds)\n",
    "\n",
    "\n",
    "def update(frame_idx):\n",
    "    for i, cam_name in enumerate(cameras):\n",
    "        ax = axs[i]\n",
    "        ax.clear()\n",
    "        ax.imshow(ds[frame_idx][\"cameras\"][cam_name][\"rgb\"])\n",
    "        # Clean title: left/front/right/back\n",
    "        ax.set_title(cam_name.split(\"_\")[0].capitalize())\n",
    "        ax.axis(\"off\")\n",
    "    # (constrained_layout handles spacing)\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=n_frames, interval=50, repeat=False)\n",
    "\n",
    "plt.close(fig)  # Close to avoid double inline display\n",
    "\n",
    "\n",
    "# Save as MP4\n",
    "ani.save(\"unreal_multicam_animation.mp4\", writer=\"ffmpeg\", dpi=200)\n",
    "\n",
    "print(f\"Animation saved as unreal_multicam_animation.mp4 ({n_frames} frames)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs and poses from output directory\n",
    "run_types = [\"base\", \"higher_elevation\", \"motion_blur\", \"no_lights\"]\n",
    "\n",
    "outputs = {}\n",
    "datasets = {}\n",
    "for run_type in run_types:\n",
    "    output_path = sorted(\n",
    "        glob.glob(str(output_dir / f\"main_pnp_vo_results_{run_type}*.pkl\"))\n",
    "    )[-1]\n",
    "    with open(output_path, \"rb\") as f:\n",
    "        output = pickle.load(f)\n",
    "    pnt.Logger.info(f\"Loaded {len(output['runs'])} runs from {output_path}\", \"Main\")\n",
    "\n",
    "    gt_poses_tmp = output[\"gt_poses\"]\n",
    "    bTw0 = pnt.invert_transform(gt_poses_tmp[0])\n",
    "    gt_poses = np.array([bTw0 @ pose for pose in gt_poses_tmp])\n",
    "\n",
    "    config = output[\"ds_config\"]\n",
    "    config[\"preload\"] = \"none\"\n",
    "    dataset = pnt.datasets.Dataset.from_config(config)\n",
    "\n",
    "    outputs[run_type] = output\n",
    "    datasets[run_type] = dataset\n",
    "\n",
    "extractors = {\n",
    "    k: pnt.FeatureExtractor.from_config(v)\n",
    "    for k, v in main_pnp_vo.extractor_configs.items()\n",
    "}\n",
    "matchers = {\n",
    "    k: pnt.FeatureMatcher.from_config(v) for k, v in main_pnp_vo.matcher_configs.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 6), dpi=300)\n",
    "if len(datasets) == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "run_display_names = {\n",
    "    \"base\": \"Baseline\",\n",
    "    \"higher_elevation\": \"Higher Sun Elevation\",\n",
    "    \"motion_blur\": \"Motion Blur\",\n",
    "    \"no_lights\": \"No Lights\",\n",
    "}\n",
    "\n",
    "\n",
    "for idx, (run_type, dataset) in enumerate(datasets.items()):\n",
    "    # Assume RGB camera is always \"front_left\"\n",
    "    rgb = dataset[63][\"cameras\"][\"front_left\"][\"rgb\"]\n",
    "    ax = axs.flatten()[idx]\n",
    "    ax.imshow(rgb)\n",
    "    ax.set_title(run_display_names[run_type])\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), dpi=300)\n",
    "\n",
    "# Plot ground truth (from base run, all will be aligned identically)\n",
    "first_run_output = next(iter(outputs.values()))\n",
    "gt_poses_tmp = first_run_output[\"gt_poses\"]\n",
    "bTw0 = pnt.invert_transform(gt_poses_tmp[0])\n",
    "gt_poses = np.array([bTw0 @ pose for pose in gt_poses_tmp])\n",
    "plt.scatter(\n",
    "    gt_poses[-1, 0, 3],\n",
    "    gt_poses[-1, 1, 3],\n",
    "    s=20,\n",
    "    label=\"Final position\",\n",
    "    c=\"k\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "ax.plot(\n",
    "    gt_poses[:, 0, 3], gt_poses[:, 1, 3], label=\"Ground Truth\", c=\"k\", lw=2, zorder=10\n",
    ")\n",
    "\n",
    "colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\"]\n",
    "\n",
    "# For storing trajectory errors\n",
    "traj_errors = {}\n",
    "\n",
    "for idx, (run_type, output) in enumerate(outputs.items()):\n",
    "    # Find SuperPoint + SuperGlue run\n",
    "    sp_sg_run = None\n",
    "    for run in output[\"runs\"]:\n",
    "        if run[\"extractor\"] == \"SuperPoint\" and run[\"matcher\"] == \"SuperGlue\":\n",
    "            sp_sg_run = run\n",
    "            break\n",
    "    if sp_sg_run is None:\n",
    "        continue\n",
    "\n",
    "    # Align estimated poses with their own first pose\n",
    "    est_poses = np.array(sp_sg_run[\"poses\"])\n",
    "    if est_poses.shape[0] == 0:\n",
    "        continue\n",
    "    bTw0_est = np.linalg.inv(est_poses[0])\n",
    "    est_poses_aligned = np.array([bTw0_est @ pose for pose in est_poses])\n",
    "    display_name = run_display_names.get(run_type, run_type)\n",
    "    ax.plot(\n",
    "        est_poses_aligned[:, 0, 3],\n",
    "        est_poses_aligned[:, 1, 3],\n",
    "        label=f\"{display_name}\",\n",
    "        lw=2,\n",
    "        color=colors[idx % len(colors)],\n",
    "        alpha=0.8,\n",
    "        zorder=idx + 1,\n",
    "    )\n",
    "    plt.scatter(est_poses_aligned[-1, 0, 3], est_poses_aligned[-1, 1, 3], s=20)\n",
    "\n",
    "    # Compute trajectory errors (translational and rotational)\n",
    "    # - Use ground truth of the same length as estimated poses\n",
    "    # - Both are aligned so direct comparison is valid\n",
    "    trans_errors = []\n",
    "    rot_errors = []\n",
    "    n_frames = min(est_poses_aligned.shape[0], gt_poses.shape[0])\n",
    "    for t in range(n_frames):\n",
    "        est = est_poses_aligned[t]\n",
    "        gt = gt_poses[t]\n",
    "        # Translational error (Euclidean norm of translation difference)\n",
    "        t_error = np.linalg.norm(est[:3, 3] - gt[:3, 3])\n",
    "        # Rotational error (angle in degrees)\n",
    "        R_diff = est[:3, :3] @ gt[:3, :3].T\n",
    "        angle_error = pnt.rotation_angle(R_diff) * pnt.DEG\n",
    "        trans_errors.append(t_error)\n",
    "        rot_errors.append(angle_error)\n",
    "    # Store errors for analysis\n",
    "    traj_errors[run_type] = {\n",
    "        \"translational\": np.array(trans_errors),\n",
    "        \"rotational\": np.array(rot_errors),\n",
    "    }\n",
    "\n",
    "ax.set_xlabel(\"X [m]\")\n",
    "ax.set_ylabel(\"Y [m]\")\n",
    "ax.axis(\"equal\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mean/median trajectory errors for each run\n",
    "print(\"Trajectory errors (SuperPoint+SuperGlue):\")\n",
    "for run_type, errors in traj_errors.items():\n",
    "    t_err = errors[\"translational\"]\n",
    "    r_err = errors[\"rotational\"]\n",
    "    print(\n",
    "        f\"{run_display_names.get(run_type, run_type)}:\"\n",
    "        f\"  mean t_err = {np.mean(t_err):.3f} m,\"\n",
    "        f\"  median t_err = {np.median(t_err):.3f} m,\"\n",
    "        f\"  mean r_err = {np.mean(r_err):.2f} deg,\"\n",
    "        f\"  median r_err = {np.median(r_err):.2f} deg\"\n",
    "    )\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gather errors and display names\n",
    "run_names_plot = [run_display_names.get(rt, rt) for rt in traj_errors.keys()]\n",
    "t_errs = [errors[\"translational\"] for errors in traj_errors.values()]\n",
    "r_errs = [errors[\"rotational\"] for errors in traj_errors.values()]\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "# Plot translational error (t_err)\n",
    "for i, (t_err, name) in enumerate(zip(t_errs, run_names_plot)):\n",
    "    axs[0].plot(t_err, label=f\"{name}\")\n",
    "axs[0].set_ylabel(\"Trans. Error [m]\")\n",
    "axs[0].set_title(\"Translational Error\")\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot rotational error (r_err)\n",
    "for i, (r_err, name) in enumerate(zip(r_errs, run_names_plot)):\n",
    "    axs[1].plot(r_err, label=f\"{name}\")\n",
    "axs[1].set_ylabel(\"Rot. Error [deg]\")\n",
    "axs[1].set_xlabel(\"Frame\")\n",
    "axs[1].set_title(\"Rotational Error\")\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Load 10 frames from the dataset\n",
    "ds_long_config = pnt.load_config(\n",
    "    {\n",
    "        \"inherit_from\": \"datasets/unreal.yaml\",\n",
    "        \"step\": 1,\n",
    "        \"basedir\": \"/home/shared_ws6/local_traverse/base_2\",\n",
    "        \"agent\": \"rover0\",\n",
    "        \"preload\": \"none\",\n",
    "        \"data_types\": [\"rgb\"],\n",
    "        \"cameras\": [\"front_left\"],\n",
    "    }\n",
    ")\n",
    "ds_long1 = pnt.datasets.Dataset.from_config(ds_long_config)\n",
    "\n",
    "ds_long_config[\"agent\"] = \"rover1\"\n",
    "ds_long_config[\"cameras\"] = [\"back_left\"]\n",
    "ds_long2 = pnt.datasets.Dataset.from_config(ds_long_config)\n",
    "\n",
    "frames1, frames2 = [], []\n",
    "for i in range(500):\n",
    "    img1 = ds_long1[i][\"cameras\"][\"front_left\"][\"rgb\"]\n",
    "    img2 = ds_long2[i][\"cameras\"][\"back_left\"][\"rgb\"]\n",
    "    frames1.append(img1)\n",
    "    frames2.append(img2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4), constrained_layout=True)\n",
    "im1 = axs[0].imshow(frames1[0])\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].set_title(\"Rover 1 - Front\")\n",
    "im2 = axs[1].imshow(frames2[0])\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].set_title(\"Rover 1 - Back\")\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    im1.set_array(frames1[i])\n",
    "    im2.set_array(frames2[i])\n",
    "    return [im1, im2]\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, animate, frames=len(frames1), interval=300, blit=True\n",
    ")\n",
    "\n",
    "plt.close(fig)\n",
    "\n",
    "# Save the animation as an MP4 file\n",
    "ani.save(\"dataset_animation.mp4\", writer=\"ffmpeg\", fps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lupnt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
