{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pylupnt as pnt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_dir = pnt.BASEDIR / \"output\" / \"2025_FeatureMatching\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ds = {\n",
    "    \"inherit_from\": \"datasets/unreal.yaml\",\n",
    "    \"basedir\": \"/home/shared_ws6/data/unreal_engine/local_traverse/base_0\",\n",
    "    \"cameras\": [\"front_left\"],\n",
    "}\n",
    "dataset = pnt.datasets.Dataset.from_config(config_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# 1. Data Extraction and Initialization\n",
    "data = dataset[10][\"cameras\"][\"front_left\"]\n",
    "rgb_img, depth_img, label_img = data[\"rgb\"], data[\"depth\"], data[\"label\"]\n",
    "\n",
    "# 2. Label Processing (Conversion and Colormap)\n",
    "label_img = np.vectorize(pnt.UnrealDataset.LABEL_UNREAL_TO_LUPNT.get)(label_img)\n",
    "unique_labels = np.unique(label_img)\n",
    "label_to_idx = {j: i for i, j in enumerate(unique_labels)}\n",
    "label_idx_img = np.vectorize(label_to_idx.get)(label_img)\n",
    "colors = [plt.get_cmap(\"tab10\")(i) for i in range(len(unique_labels))]\n",
    "discrete_cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# 3. Depth Normalization (Corrected log_depth typo)\n",
    "log_depth = np.log10(np.clip(depth_img, 1e-6, None))\n",
    "log_min, log_max = np.floor(np.nanmin(log_depth[log_depth > 0])), np.ceil(\n",
    "    np.nanmax(log_depth[log_depth > 0])\n",
    ")\n",
    "depth_ticks = np.arange(log_min, log_max + 1)\n",
    "\n",
    "# 4. Figure and Axes Setup (Modification here: Removing fixed height from figsize)\n",
    "fig_width = 12\n",
    "fig, axes = plt.subplots(\n",
    "    1,\n",
    "    4,\n",
    "    figsize=(fig_width, fig_width / 4),  # Estimate height for initialization\n",
    "    gridspec_kw={\"width_ratios\": [1, 1, 1, 1]},\n",
    ")\n",
    "\n",
    "# --- Plot 1: RGB Image ---\n",
    "plt.sca(axes[0])\n",
    "plt.imshow(rgb_img)\n",
    "plt.title(\"RGB\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# --- Plot 2: Depth Image with Custom Colorbar ---\n",
    "plt.sca(axes[1])\n",
    "im1 = plt.imshow(log_depth, cmap=\"viridis\", vmin=log_min, vmax=log_max)\n",
    "plt.title(\"Depth\")\n",
    "plt.axis(\"off\")\n",
    "cax = inset_axes(\n",
    "    axes[1],\n",
    "    width=\"4%\",\n",
    "    height=\"40%\",\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.7, 0.09, 1, 1),\n",
    "    bbox_transform=axes[1].transAxes,\n",
    ")\n",
    "cbar1 = fig.colorbar(im1, cax=cax, ticks=depth_ticks)\n",
    "cbar1.ax.tick_params(labelsize=\"small\", length=0, colors=\"white\")\n",
    "cbar1.set_ticklabels([f\"$10^{{{int(tick)}}}$\" for tick in depth_ticks])\n",
    "cbar1.set_label(\"Depth [m]\", fontsize=\"small\", labelpad=8, color=\"white\")\n",
    "[label.set_color(\"white\") for label in cbar1.ax.get_yticklabels()]\n",
    "\n",
    "# --- Plot 3: Label Image with Legend ---\n",
    "plt.sca(axes[2])\n",
    "im2 = plt.imshow(label_idx_img, cmap=discrete_cmap, vmin=0, vmax=len(unique_labels) - 1)\n",
    "plt.title(\"Label\")\n",
    "plt.axis(\"off\")\n",
    "label_names = [pnt.LABEL_NAMES[label] for label in unique_labels]\n",
    "patches = [\n",
    "    mpatches.Patch(color=colors[i], label=name, linewidth=1, alpha=1)\n",
    "    for i, name in enumerate(label_names)\n",
    "]\n",
    "plt.legend(\n",
    "    handles=patches,\n",
    "    loc=\"upper right\",\n",
    "    bbox_to_anchor=(0.01, 0.01, 0.99, 0.99),\n",
    "    bbox_transform=axes[2].transAxes,\n",
    "    fontsize=\"small\",\n",
    "    ncol=2,\n",
    "    frameon=True,\n",
    "    borderaxespad=0.1,\n",
    ")\n",
    "\n",
    "# --- Plot 4: Trajectory (Modified for Limit Ratio) ---\n",
    "plt.sca(axes[3])\n",
    "plt.plot(dataset.positions[:, 1], dataset.positions[:, 0])\n",
    "plt.scatter(dataset.positions[0, 1], dataset.positions[0, 0])\n",
    "plt.xlabel(\"X [m]\")\n",
    "plt.ylabel(\"Y [m]\")\n",
    "plt.title(\"Trajectory\")\n",
    "plt.grid(True)\n",
    "plt.axis(\"equal\")\n",
    "\n",
    "ratio = rgb_img.shape[0] / rgb_img.shape[1]\n",
    "axes[3].set_box_aspect(ratio)\n",
    "xlims, ylims = plt.xlim(), plt.ylim()\n",
    "max_range = np.maximum(xlims[1] - xlims[0], (ylims[1] - ylims[0]) / ratio)\n",
    "new_range_x, new_range_y = max_range, max_range * ratio\n",
    "plt.xlim(np.mean(xlims) - new_range_x / 2, np.mean(xlims) + new_range_x / 2)\n",
    "plt.ylim(np.mean(ylims) - new_range_y / 2, np.mean(ylims) + new_range_y / 2)\n",
    "\n",
    "# --- Final Save and Display ---\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "plt.savefig(output_dir / \"figures/unreal_rgb_depth_label.pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features_by_depth(feats: pnt.Features, data: pnt.ImageData):\n",
    "    u = feats.uv.astype(np.int32)\n",
    "    depth = data.depth[u[:, 1], u[:, 0]]\n",
    "    indices = np.where((depth > 0) & (depth < 1e3) & ~np.isnan(depth))[0]\n",
    "    feats.filter(indices)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(feats1, feats2, img_data1, img_data2, matches, filename=None):\n",
    "    h, w = img_data1.rgb.shape[:2]\n",
    "\n",
    "    # Check valid feature coordinates in image 1\n",
    "    u1 = feats1.uv[:, 0].astype(np.int32).clip(0, w - 1)\n",
    "    v1 = feats1.uv[:, 1].astype(np.int32).clip(0, h - 1)\n",
    "\n",
    "    depth1 = img_data1.depth[v1, u1]\n",
    "\n",
    "    # Convert to 3D world coordinates\n",
    "    xyz_c1 = pnt.uv_to_xyz(feats1.uv, depth1, img_data1.intrinsics)\n",
    "    xyz1_w = pnt.apply_transform(img_data1.world_T_cam, xyz_c1)\n",
    "\n",
    "    # Project to image 2\n",
    "    uv2_true, depth2 = pnt.xyz_to_uv(\n",
    "        xyz1_w, img_data2.intrinsics, img_data2.world_T_cam, return_depth=True\n",
    "    )\n",
    "\n",
    "    # Filter valid projections\n",
    "    valid_mask2: np.ndarray = (\n",
    "        (depth1 > 0)\n",
    "        & (depth2 > 0)\n",
    "        & (0 <= uv2_true[:, 0])\n",
    "        & (uv2_true[:, 0] < w)\n",
    "        & (0 <= uv2_true[:, 1])\n",
    "        & (uv2_true[:, 1] < h)\n",
    "    )\n",
    "\n",
    "    # Match distance\n",
    "    gt_thresh = 0.01 * w\n",
    "    dist_match = np.linalg.norm(\n",
    "        uv2_true[matches.indexes[:, 0]] - feats2.uv[matches.indexes[:, 1]], axis=1\n",
    "    )\n",
    "    dists_normed = np.clip(dist_match / gt_thresh / 2.0, 0, 1)\n",
    "    dists_normed = np.where(np.isnan(dists_normed), 1.0, dists_normed)\n",
    "    match_colors = np.vstack(\n",
    "        [dists_normed, 1 - dists_normed, np.zeros(len(dists_normed))]\n",
    "    ).T\n",
    "\n",
    "    # Precision and recall\n",
    "    matched = np.zeros(len(feats1), dtype=np.bool)\n",
    "    matched[matches.indexes[:, 0]] = True\n",
    "    dist_feats1 = np.full(len(feats1), np.nan)\n",
    "    dist_feats1[matches.indexes[:, 0]] = dist_match\n",
    "    pos = (dist_feats1 < gt_thresh) & valid_mask2\n",
    "    neg = (dist_feats1 >= gt_thresh) | ~valid_mask2\n",
    "    tp = matched & pos\n",
    "    fp = matched & neg\n",
    "    fn = ~matched & pos\n",
    "    prec = np.sum(tp) / (np.sum(tp) + np.sum(fp))\n",
    "    rec = np.sum(tp) / (np.sum(tp) + np.sum(fn))\n",
    "\n",
    "    print(f\"Positive: {np.sum(pos)}, Negative: {np.sum(neg)}\")\n",
    "    print(f\"TP: {np.sum(tp)}, FP: {np.sum(fp)}, FN: {np.sum(fn)}\")\n",
    "    print(f\"Precision: {prec:.2f}, Recall: {rec:.2f}\")\n",
    "\n",
    "    # Subsample matches\n",
    "    n_matches = len(matches.indexes)\n",
    "    sort_keys = np.lexsort(\n",
    "        (matches.indexes[:, 1], matches.indexes[:, 0], matches.distances)\n",
    "    )\n",
    "    idxs_match = sort_keys[:n_matches]\n",
    "    idxs_uv1, idxs_uv2 = matches.indexes[idxs_match].T\n",
    "\n",
    "    pnp_config = {\"threshold\": 1.0, \"confidence\": 0.999, \"max_iterations\": 1000}\n",
    "    pnp_solver = pnt.PnpSolver(pnp_config)\n",
    "    K = pnt.make_camera_matrix(img_data2.intrinsics)\n",
    "    pnp_result = pnp_solver.solve(\n",
    "        xyz_c1[matches.indexes[:, 0]], feats2.uv[matches.indexes[:, 1]], K\n",
    "    )\n",
    "\n",
    "    # Compute error\n",
    "    c2Tc1_pnp = pnp_result.tgt_T_src\n",
    "    wTc1 = img_data1.world_T_cam\n",
    "    c2Tw = pnt.invert_transform(img_data2.world_T_cam)\n",
    "    c2Tc1_gt = c2Tw @ wTc1\n",
    "\n",
    "    ea_t_pnp = np.linalg.norm(c2Tc1_gt[:3, 3] - c2Tc1_pnp[:3, 3])\n",
    "    ea_R_pnp = pnt.rotation_angle(c2Tc1_pnp[:3, :3] @ c2Tc1_gt[:3, :3].T) * pnt.DEG\n",
    "\n",
    "    print(f\"Translation error: {ea_t_pnp:.2f} m\")\n",
    "    print(f\"Rotation error: {ea_R_pnp:.2f} deg\")\n",
    "\n",
    "    h, w = img_data1[\"rgb\"].shape[:2]\n",
    "    ws = 10\n",
    "    sep = np.ones((h, ws, 3))\n",
    "\n",
    "    # Features\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(np.hstack([img_data1.rgb, sep, img_data2.rgb]))\n",
    "    plt.scatter(feats1.uv[:, 0], feats1.uv[:, 1], color=\"cyan\", s=2)\n",
    "    plt.scatter(feats2.uv[:, 0] + w + ws, feats2.uv[:, 1], color=\"magenta\", s=2)\n",
    "    plt.scatter([], [], color=\"cyan\", s=10, label=\"Extracted Features 1\")\n",
    "    plt.scatter([], [], color=\"magenta\", s=10, label=\"Extracted Features 2\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.xlim(0, 2 * w + ws)\n",
    "    plt.ylim(h, 0)\n",
    "    plt.legend(loc=\"upper right\", framealpha=1.0)\n",
    "    plt.tight_layout()\n",
    "    if filename is not None:\n",
    "        plt.savefig(\n",
    "            output_dir / f\"figures/{filename}_all.pdf\", dpi=300, bbox_inches=\"tight\"\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "    # FP, FN, TP\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(np.hstack([img_data1.rgb, sep, img_data2.rgb]))\n",
    "    plt.scatter(feats1.uv[fp, 0], feats1.uv[fp, 1], color=\"red\", s=2)\n",
    "    plt.scatter(feats1.uv[fn, 0], feats1.uv[fn, 1], color=\"yellow\", s=2)\n",
    "    plt.scatter(feats1.uv[tp, 0], feats1.uv[tp, 1], color=\"lime\", s=2)\n",
    "    plt.scatter(\n",
    "        uv2_true[tp & valid_mask2, 0] + w + ws,\n",
    "        uv2_true[tp & valid_mask2, 1],\n",
    "        color=\"lime\",\n",
    "        s=2,\n",
    "    )\n",
    "    plt.scatter(\n",
    "        uv2_true[fp & valid_mask2, 0] + w + ws,\n",
    "        uv2_true[fp & valid_mask2, 1],\n",
    "        color=\"red\",\n",
    "        s=2,\n",
    "    )\n",
    "    plt.scatter(\n",
    "        uv2_true[fn & valid_mask2, 0] + w + ws,\n",
    "        uv2_true[fn & valid_mask2, 1],\n",
    "        color=\"yellow\",\n",
    "        s=2,\n",
    "    )\n",
    "    plt.scatter([], [], color=\"lime\", s=10, label=f\"Correct ({np.sum(tp)} TP)\")\n",
    "    plt.scatter([], [], color=\"red\", s=10, label=f\"Incorrect ({np.sum(fp)} FP)\")\n",
    "    plt.scatter([], [], color=\"yellow\", s=10, label=f\"Missed ({np.sum(fn)} FN)\")\n",
    "    plt.scatter([], [], s=0.001, label=f\"Precision: {prec:.2f}, Recall: {rec:.2f}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.xlim(0, 2 * w + ws)\n",
    "    plt.ylim(h, 0)\n",
    "    plt.legend(loc=\"upper right\", framealpha=1.0)\n",
    "    plt.tight_layout()\n",
    "    if filename is not None:\n",
    "        plt.savefig(\n",
    "            output_dir / f\"figures/{filename}_fp_fn.pdf\", dpi=300, bbox_inches=\"tight\"\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "    # Matches\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(np.hstack([img_data1.rgb, sep, img_data2.rgb]))\n",
    "    # plt.scatter(feats1.uv[idxs_uv1, 0], feats1.uv[idxs_uv1, 1], color=\"cyan\", s=10)\n",
    "    # plt.scatter(feats2.uv[idxs_uv2, 0] + w + ws, feats2.uv[idxs_uv2, 1], color=\"cyan\", s=10)\n",
    "    for i, j, k in zip(idxs_uv1, idxs_uv2, idxs_match):\n",
    "        pt1, pt2 = feats1.uv[i], feats2.uv[j]\n",
    "        plt.plot(\n",
    "            [pt1[0], pt2[0] + w + ws],\n",
    "            [pt1[1], pt2[1]],\n",
    "            \"-\",\n",
    "            color=match_colors[k],\n",
    "            lw=1.0,\n",
    "            zorder=15,\n",
    "        )\n",
    "    plt.axis(\"off\")\n",
    "    plt.plot([], [], color=\"lime\", lw=2.0, label=\"Low Error\")\n",
    "    plt.plot([], [], color=\"red\", lw=2.0, label=\"High Error\")\n",
    "    plt.xlim(0, 2 * w + ws)\n",
    "    plt.ylim(h, 0)\n",
    "    plt.legend(loc=\"upper right\", framealpha=1.0)\n",
    "    plt.tight_layout()\n",
    "    if filename is not None:\n",
    "        plt.savefig(\n",
    "            output_dir / f\"figures/{filename}_matches.pdf\", dpi=300, bbox_inches=\"tight\"\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_unreal_simple import process_config\n",
    "\n",
    "# Extractors and matchers base configurations\n",
    "extractor_configs = {\n",
    "    \"SuperPoint\": {\"class\": \"SuperPoint\"},\n",
    "    \"SIFT\": {\"class\": \"Sift\"},\n",
    "    \"ORB\": {\"class\": \"Orb\"},\n",
    "    \"AKAZE\": {\"class\": \"Akaze\"},\n",
    "    \"BRISK\": {\"class\": \"Brisk\"},\n",
    "}\n",
    "\n",
    "matcher_configs = {\n",
    "    \"LightGlue\": {\"class\": \"LightGlue\"},\n",
    "    \"SuperGlue\": {\"class\": \"SuperGlue\"},\n",
    "    \"BruteForce\": {\"class\": \"BruteForceMatcher\"},\n",
    "    \"Flann\": {\"class\": \"FlannMatcher\"},\n",
    "}\n",
    "\n",
    "# Generate compatible combinations using process_config\n",
    "combinations = []\n",
    "for e_name in extractor_configs.keys():\n",
    "    if e_name not in extractor_configs:\n",
    "        continue\n",
    "    for m_name in matcher_configs.keys():\n",
    "        if m_name not in matcher_configs:\n",
    "            continue\n",
    "\n",
    "        e_cfg = extractor_configs[e_name]\n",
    "        m_cfg = matcher_configs[m_name]\n",
    "        e_cfg_processed, m_cfg_processed = process_config(e_name, e_cfg, m_name, m_cfg)\n",
    "\n",
    "        if e_cfg_processed is not None and m_cfg_processed is not None:\n",
    "            combinations.append((e_name, e_cfg_processed, m_name, m_cfg_processed))\n",
    "\n",
    "# Create extractors and matchers from processed configs\n",
    "# Create per combination to handle cases where extractor config might differ per matcher\n",
    "extractors = {}\n",
    "matchers = {}\n",
    "\n",
    "for e_name, e_cfg, m_name, m_cfg in combinations:\n",
    "    combo_key = (e_name, m_name)\n",
    "\n",
    "    # Create extractor for this specific combination (config may vary per matcher)\n",
    "    if combo_key not in extractors:\n",
    "        extractors[combo_key] = pnt.FeatureExtractor.from_config(e_cfg)\n",
    "\n",
    "    # Create matcher for this specific combination (config may vary per extractor)\n",
    "    if combo_key not in matchers:\n",
    "        matchers[combo_key] = pnt.FeatureMatcher.from_config(m_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (e_name, e_cfg, m_name, m_cfg) in enumerate(combinations):\n",
    "    print(f\"{i}: {e_name} + {m_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_name = \"front_left\"\n",
    "e_name = \"SuperPoint\"\n",
    "m_name = \"SuperGlue\"\n",
    "\n",
    "img_data1 = dataset[114][\"cameras\"][cam_name]\n",
    "img_data2 = dataset[124][\"cameras\"][cam_name]\n",
    "\n",
    "# Use extractor for this specific combination\n",
    "feats1 = extractors[(e_name, m_name)].extract(img_data1.rgb)\n",
    "feats2 = extractors[(e_name, m_name)].extract(img_data2.rgb)\n",
    "\n",
    "feats1 = filter_features_by_depth(feats1, img_data1)\n",
    "feats2 = filter_features_by_depth(feats2, img_data2)\n",
    "\n",
    "matches = matchers[(e_name, m_name)].match(feats1, feats2)\n",
    "\n",
    "filename = \"extracted_features_consecutive\"\n",
    "plot_features(feats1, feats2, img_data1, img_data2, matches, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_name = \"front_left\"\n",
    "e_name = \"SuperPoint\"\n",
    "m_name = \"SuperGlue\"\n",
    "filename = \"extracted_features_nonconsecutive\"\n",
    "\n",
    "img_data1 = dataset[114][\"cameras\"][cam_name]\n",
    "img_data2 = dataset[180][\"cameras\"][cam_name]\n",
    "\n",
    "# Use extractor for this specific combination\n",
    "combo_key = (e_name, m_name)\n",
    "feats1 = extractors[combo_key].extract(img_data1.rgb)\n",
    "feats2 = extractors[combo_key].extract(img_data2.rgb)\n",
    "\n",
    "feats1 = filter_features_by_depth(feats1, img_data1)\n",
    "feats2 = filter_features_by_depth(feats2, img_data2)\n",
    "\n",
    "matches = matchers[(e_name, m_name)].match(feats1, feats2)\n",
    "plot_features(feats1, feats2, img_data1, img_data2, matches, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_name = \"front_left\"\n",
    "filename = \"extracted_features_nonconsecutive\"\n",
    "img_data1 = dataset[114][\"cameras\"][cam_name]\n",
    "img_data2 = dataset[124][\"cameras\"][cam_name]\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(10, 7))\n",
    "\n",
    "\n",
    "h, w = img_data1[\"rgb\"].shape[:2]\n",
    "ws = 10\n",
    "sep = np.ones((h, ws, 3))\n",
    "\n",
    "plt.sca(axes.flat[0])\n",
    "plt.imshow(np.hstack([img_data1[\"rgb\"], sep, img_data2[\"rgb\"]]))\n",
    "plt.axis(\"off\")\n",
    "plt.xlim(0, 2 * w + ws)\n",
    "plt.ylim(h, 0)\n",
    "plt.title(\"RGB\")\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for i, (e_name, e_cfg, m_name, m_cfg) in enumerate(combinations):\n",
    "    # Feature extraction and matching\n",
    "    # Use extractor for this specific combination\n",
    "    feats1 = extractors[(e_name, m_name)].extract(img_data1.rgb)\n",
    "    feats2 = extractors[(e_name, m_name)].extract(img_data2.rgb)\n",
    "    feats1 = filter_features_by_depth(feats1, img_data1)\n",
    "    feats2 = filter_features_by_depth(feats2, img_data2)\n",
    "    matches = matchers[(e_name, m_name)].match(feats1, feats2)\n",
    "    print(f\"{i}: {e_name} + {m_name}\")\n",
    "\n",
    "    # Check valid feature coordinates in image 1\n",
    "    h, w = img_data1.rgb.shape[:2]\n",
    "    u1 = feats1.uv[:, 0].astype(np.int32).clip(0, w - 1)\n",
    "    v1 = feats1.uv[:, 1].astype(np.int32).clip(0, h - 1)\n",
    "    depth1 = img_data1.depth[v1, u1]\n",
    "\n",
    "    # Convert to 3D world coordinates\n",
    "    xyz_c1 = pnt.uv_to_xyz(feats1.uv, depth1, img_data1.intrinsics)\n",
    "    xyz1_w = pnt.apply_transform(img_data1.world_T_cam, xyz_c1)\n",
    "\n",
    "    # Project to image 2\n",
    "    uv2_true, depth2 = pnt.xyz_to_uv(\n",
    "        xyz1_w, img_data2.intrinsics, img_data2.world_T_cam, return_depth=True\n",
    "    )\n",
    "\n",
    "    # Compute pairwise distances between uv2_true and feats2.uv\n",
    "    all_dists = np.linalg.norm(uv2_true[:, None, :] - feats2.uv[None, :, :], axis=2)\n",
    "    dist_feats2true = np.min(all_dists, axis=0)\n",
    "\n",
    "    # Match distance\n",
    "    gt_thresh = 0.01 * w\n",
    "    dist_match = dist_feats2true[matches.indexes[:, 1]]\n",
    "    dists_normed = np.clip(dist_match / gt_thresh / 2.0, 0, 1)\n",
    "    colors = np.vstack([dists_normed, 1 - dists_normed, np.zeros(len(dists_normed))]).T\n",
    "\n",
    "    # Subsample matches\n",
    "    # Sort deterministically: by distance first, then by match index to break ties\n",
    "    n_matches = len(matches.indexes)\n",
    "    # Use lexsort for deterministic tie-breaking: sort by distance, then by index\n",
    "    sort_keys = (matches.distances, np.arange(len(matches.distances)))\n",
    "    idxs_match = np.lexsort(sort_keys)[:n_matches]\n",
    "    idxs_uv1, idxs_uv2 = matches.indexes[idxs_match].T\n",
    "\n",
    "    plt.sca(axes.flat[i + 1])\n",
    "    plt.imshow(np.hstack([img_data1[\"rgb\"], sep, img_data2[\"rgb\"]]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.xlim(0, 2 * w + ws)\n",
    "    plt.ylim(h, 0)\n",
    "    plt.title(f\"{e_name} + {m_name}\")\n",
    "\n",
    "    for k, (i, j) in enumerate(zip(idxs_uv1, idxs_uv2)):\n",
    "        pt1, pt2 = feats1.uv[i], feats2.uv[j]\n",
    "        plt.plot(\n",
    "            [pt1[0], pt2[0] + w + ws],\n",
    "            [pt1[1], pt2[1]],\n",
    "            \"-\",\n",
    "            color=colors[idxs_match[k]],\n",
    "            lw=1.0,\n",
    "            zorder=15,\n",
    "        )\n",
    "    plt.axis(\"off\")\n",
    "    plt.plot([], [], color=\"lime\", lw=2.0, label=\"Low Error\")\n",
    "    plt.plot([], [], color=\"red\", lw=2.0, label=\"High Error\")\n",
    "    plt.xlim(0, 2 * w + ws)\n",
    "    plt.ylim(h, 0)\n",
    "    plt.title(f\"{e_name} + {m_name}\")\n",
    "    # plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / f\"figures/feature_matching_all.pdf\", dpi=300, bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot just the feature extractors (all detectors on their own keypoints and scores, no matching)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "h, w = img_data1.rgb.shape[:2]\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plt.imshow(img_data1[\"rgb\"])\n",
    "plt.xlim(0, w)\n",
    "plt.ylim(h, 0)\n",
    "plt.title(\"RGB\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Then each extractor\n",
    "plotted_extractors = set()\n",
    "for i, ((e_name, m_name), extractor) in enumerate(extractors.items()):\n",
    "    if e_name in plotted_extractors:\n",
    "        continue\n",
    "    print(f\"{i}: {e_name} + {m_name}\")\n",
    "    feats = extractor.extract(img_data1.rgb)\n",
    "    plt.sca(axes[len(plotted_extractors) + 1])\n",
    "    plt.imshow(img_data1[\"rgb\"])\n",
    "    plt.scatter(feats.uv[:, 0], feats.uv[:, 1], color=\"cyan\", s=2)\n",
    "    plt.xlim(0, w)\n",
    "    plt.ylim(h, 0)\n",
    "    plt.title(f\"{e_name}\")\n",
    "    plt.axis(\"off\")\n",
    "    plotted_extractors.add(e_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / f\"figures/features_all_extractors.pdf\", dpi=200, bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lusnar_dataset_config = {\n",
    "    \"inherit_from\": \"lusnar.yaml\",\n",
    "    \"preload\": \"none\",\n",
    "}\n",
    "lusnar_dataset = pnt.Dataset.from_config(lusnar_dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lusnar_dataset[0][\"cameras\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_name = \"front_left\"\n",
    "e_name = \"ORB\"\n",
    "m_name = \"Flann\"\n",
    "filename = \"tmp\"\n",
    "\n",
    "img_data1 = lusnar_dataset[0][\"cameras\"][cam_name]\n",
    "img_data2 = lusnar_dataset[1][\"cameras\"][cam_name]\n",
    "\n",
    "# Use extractor for this specific combination\n",
    "combo_key = (e_name, m_name)\n",
    "feats1 = extractors[combo_key].extract(img_data1.rgb)\n",
    "feats2 = extractors[combo_key].extract(img_data2.rgb)\n",
    "\n",
    "feats1 = filter_features_by_depth(feats1, img_data1)\n",
    "feats2 = filter_features_by_depth(feats2, img_data2)\n",
    "\n",
    "matches = matchers[(e_name, m_name)].match(feats1, feats2)\n",
    "plot_features(feats1, feats2, img_data1, img_data2, matches, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lupnt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
