{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Increase plot resolution\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Directories\n",
    "models_dir = Path(\n",
    "    \"/home/guillemc/dev/LuPNT-private/output/2025_FeatureMatching/eval_results_models\"\n",
    ")\n",
    "legacy_dir = Path(\n",
    "    \"/home/guillemc/dev/LuPNT-private/output/2025_FeatureMatching/eval_results\"\n",
    ")\n",
    "\n",
    "all_data = []\n",
    "all_per_pair_list = []\n",
    "\n",
    "# Dataset Name Mapping (Prettify)\n",
    "dataset_map = {\n",
    "    \"short_base\": \"Baseline\",\n",
    "    \"short_camera_effects\": \"Camera Effects\",\n",
    "    \"short_higher_elevation\": \"Higher Sun Elevation\",\n",
    "    \"short_no_lights\": \"No Lights\",\n",
    "    \"long_base\": \"Long Base\",\n",
    "    \"long_camera_effects\": \"Long Camera Effects\",\n",
    "    \"long_higher_elevation\": \"Long Higher Elevation\",\n",
    "    \"long_no_lights\": \"Long No Lights\",\n",
    "    \"rover_0\": \"Spirals\",\n",
    "}\n",
    "\n",
    "# Model Name Mapping (Renaming)\n",
    "model_name_map = {\n",
    "    \"SuperPoint+LightGlue_Spirals\": \"Finetuned\",\n",
    "    # We will filter out the others, but mapping them just in case\n",
    "    \"lightglue_spirals_v1\": \"SuperPoint+LightGlue (Spirals)\",\n",
    "    \"lightglue_unreal_base1\": \"SuperPoint+LightGlue (Traverse)\",\n",
    "    \"spirals_seg_rover0\": \"SuperPoint+LightGlue (Spirals+Segmentation)\",\n",
    "}\n",
    "\n",
    "# Skip list (Dumb/Test models AND models user wants to hide)\n",
    "skip_patterns = [\n",
    "    \"semantic_test\",\n",
    "    \"local_traverse_fov90\",\n",
    "    \"spirals_20251211\",\n",
    "    # User requested ONLY \"Spirals Legacy\" (now \"Finetuned\")\n",
    "    \"lightglue_spirals_v1\",\n",
    "    \"lightglue_unreal_base1\",\n",
    "    \"spirals_seg_rover0\",\n",
    "]\n",
    "\n",
    "# --- 1. Load Trained Models ---\n",
    "print(f\"Scanning models in {models_dir}...\")\n",
    "if models_dir.exists():\n",
    "    for model_path in models_dir.iterdir():\n",
    "        if not model_path.is_dir():\n",
    "            continue\n",
    "        raw_model_name = model_path.name\n",
    "\n",
    "        # Filtering Models\n",
    "        if any(skip in raw_model_name for skip in skip_patterns):\n",
    "            continue\n",
    "\n",
    "        # Determine Display Name\n",
    "        model_display_name = raw_model_name  # Default\n",
    "\n",
    "        # Check for user-defined mapping (prefix match)\n",
    "        for key, val in model_name_map.items():\n",
    "            if key in raw_model_name:\n",
    "                model_display_name = val\n",
    "                break\n",
    "\n",
    "        # Fallback for others\n",
    "        if model_display_name == raw_model_name and \"spirals\" in raw_model_name.lower():\n",
    "            model_display_name = f\"Finetuned ({raw_model_name})\"\n",
    "\n",
    "        for dataset_path in model_path.iterdir():\n",
    "            if not dataset_path.is_dir():\n",
    "                continue\n",
    "            raw_dataset_name = dataset_path.name\n",
    "\n",
    "            # Filter Datasets: ONLY short_*, exclude rover_0/Spirals\n",
    "            if \"short\" not in raw_dataset_name:\n",
    "                continue\n",
    "\n",
    "            dataset_name = dataset_map.get(\n",
    "                raw_dataset_name, raw_dataset_name.replace(\"_\", \" \").title()\n",
    "            )\n",
    "\n",
    "            for step_file in dataset_path.glob(\"step_*.pkl\"):\n",
    "                try:\n",
    "                    step = int(step_file.stem.split(\"_\")[1])\n",
    "                    with open(step_file, \"rb\") as f:\n",
    "                        data = pickle.load(f)\n",
    "\n",
    "                    metrics = data[\"results\"]\n",
    "                    for method, res in metrics.items():\n",
    "                        # Summary\n",
    "                        if \"summary\" in res:\n",
    "                            row = res[\"summary\"].copy()\n",
    "                            row[\"Model Type\"] = \"Finetuned\"\n",
    "                            row[\"Model\"] = model_display_name\n",
    "                            row[\"Method\"] = method\n",
    "                            row[\"Dataset\"] = dataset_name\n",
    "                            row[\"Step\"] = step\n",
    "                            if \"abs_loc_t_error\" in row:\n",
    "                                row[\"Abs Trans Error (m)\"] = row[\"abs_loc_t_error\"]\n",
    "                            if \"rel_pose_r_error\" in row:\n",
    "                                row[\"Rel Rot Error (deg)\"] = row[\"rel_pose_r_error\"]\n",
    "                            all_data.append(row)\n",
    "\n",
    "                        # Per Pair (Not loading for summary plot notebook to save memory)\n",
    "                        # if \"per_pair\" in res:\n",
    "                        #     pass\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "# --- 2. Load Legacy Results (Baselines) ---\n",
    "print(f\"Scanning legacy results in {legacy_dir}...\")\n",
    "if legacy_dir.exists():\n",
    "    for dataset_path in legacy_dir.iterdir():\n",
    "        if not dataset_path.is_dir():\n",
    "            continue\n",
    "        raw_dataset_name = dataset_path.name\n",
    "        dataset_name = dataset_map.get(\n",
    "            raw_dataset_name, raw_dataset_name.replace(\"_\", \" \").title()\n",
    "        )\n",
    "\n",
    "        for agent_path in dataset_path.iterdir():  # e.g. rover_0\n",
    "            if not agent_path.is_dir():\n",
    "                continue\n",
    "\n",
    "            # Filter Datasets: ONLY short_*, exclude rover_0/Spirals\n",
    "            if \"short\" not in raw_dataset_name:\n",
    "                continue\n",
    "\n",
    "            for step_file in agent_path.glob(\"*.pkl\"):\n",
    "                try:\n",
    "                    parts = step_file.stem.split(\"_\")\n",
    "                    if len(parts) >= 2 and parts[0] == \"step\":\n",
    "                        try:\n",
    "                            step = int(parts[1])\n",
    "                        except:\n",
    "                            continue\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    with open(step_file, \"rb\") as f:\n",
    "                        data = pickle.load(f)\n",
    "\n",
    "                    metrics = data.get(\"results\", {})\n",
    "                    for method, res in metrics.items():\n",
    "                        # Determine Label: Just \"Detection+Matching\" (e.g. SuperPoint+LightGlue)\n",
    "                        # Remove \"Baseline\" prefix to match user request\n",
    "                        model_label = method\n",
    "\n",
    "                        # Summary\n",
    "                        if \"summary\" in res:\n",
    "                            row = res[\"summary\"].copy()\n",
    "                            row[\"Model Type\"] = \"Baseline\"\n",
    "                            row[\"Model\"] = (\n",
    "                                model_label  # Use the method name directly as the Model label\n",
    "                            )\n",
    "                            row[\"Method\"] = method\n",
    "                            row[\"Dataset\"] = dataset_name\n",
    "                            row[\"Step\"] = step\n",
    "                            if \"rel_pose_r_error\" in row:\n",
    "                                row[\"Rel Rot Error (deg)\"] = row[\"rel_pose_r_error\"]\n",
    "                            if \"rel_pose_t_error\" in row:\n",
    "                                row[\"Trans Error (m)\"] = row[\"rel_pose_t_error\"]\n",
    "                            all_data.append(row)\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "df_summary = pd.DataFrame(all_data)\n",
    "\n",
    "print(f\"Loaded {len(df_summary)} total summary records.\")\n",
    "if not df_summary.empty:\n",
    "    # Also for summary df\n",
    "    df_summary[\"Labels\"] = df_summary[\"Model\"]\n",
    "\n",
    "    # 2b. Completeness Table\n",
    "    # Create a pivot table showing which Steps exist for each Model+Dataset\n",
    "    print(\"Generating Completeness Table...\")\n",
    "    completeness = (\n",
    "        df_summary.groupby([\"Dataset\", \"Labels\"])[\"Step\"]\n",
    "        .apply(lambda x: sorted(list(set(x))))\n",
    "        .unstack(fill_value=\"-\")\n",
    "    )\n",
    "\n",
    "    # Style the table\n",
    "    # We can just display it as a dataframe\n",
    "    display(completeness)\n",
    "\n",
    "    display(df_summary.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 8. Summary Heatmaps (Detailed Absolute Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_metrics = [\n",
    "    # Matching Statistics\n",
    "    (\"mnum_matches\", \"Mean Num Matches\", \"float\"),\n",
    "    (\"median_num_matches\", \"Median Num Matches\", \"float\"),\n",
    "    (\"mnum_keypoints0\", \"Mean Num Keypoints 0\", \"float\"),\n",
    "    (\"median_num_keypoints0\", \"Median Num Keypoints 0\", \"float\"),\n",
    "    (\"mnum_keypoints1\", \"Mean Num Keypoints 1\", \"float\"),\n",
    "    (\"median_num_keypoints1\", \"Median Num Keypoints 1\", \"float\"),\n",
    "    (\"mnum_keypoints\", \"Mean Num Keypoints\", \"float\"),\n",
    "    (\"median_num_keypoints\", \"Median Num Keypoints\", \"float\"),\n",
    "    # Epipolar Precision\n",
    "    (\"mepi_prec@1e-4\", \"Mean Epi Prec @ 1e-4\", \"float\"),\n",
    "    (\"median_epi_prec@1e-4\", \"Median Epi Prec @ 1e-4\", \"float\"),\n",
    "    (\"mepi_prec@5e-4\", \"Mean Epi Prec @ 5e-4\", \"float\"),\n",
    "    (\"median_epi_prec@5e-4\", \"Median Epi Prec @ 5e-4\", \"float\"),\n",
    "    (\"mepi_prec@1e-3\", \"Mean Epi Prec @ 1e-3\", \"float\"),\n",
    "    (\"median_epi_prec@1e-3\", \"Median Epi Prec @ 1e-3\", \"float\"),\n",
    "    # Reprojection Precision\n",
    "    (\"mreproj_prec@1px\", \"Mean Reproj Prec @ 1px\", \"float\"),\n",
    "    (\"median_reproj_prec@1px\", \"Median Reproj Prec @ 1px\", \"float\"),\n",
    "    (\"mreproj_prec@3px\", \"Mean Reproj Prec @ 3px\", \"float\"),\n",
    "    (\"median_reproj_prec@3px\", \"Median Reproj Prec @ 3px\", \"float\"),\n",
    "    (\"mreproj_prec@5px\", \"Mean Reproj Prec @ 5px\", \"float\"),\n",
    "    (\"median_reproj_prec@5px\", \"Median Reproj Prec @ 5px\", \"float\"),\n",
    "    # Covisibility\n",
    "    (\"mcovisible\", \"Mean Covisible\", \"float\"),\n",
    "    (\"median_covisible\", \"Median Covisible\", \"float\"),\n",
    "    (\"mcovisible_percent\", \"Mean Covisible %\", \"float\"),\n",
    "    (\"median_covisible_percent\", \"Median Covisible %\", \"float\"),\n",
    "    # Ground Truth Recall/Precision\n",
    "    (\"mgt_match_recall@3px\", \"Mean GT Match Recall @ 3px\", \"float\"),\n",
    "    (\"median_gt_match_recall@3px\", \"Median GT Match Recall @ 3px\", \"float\"),\n",
    "    (\"mgt_match_precision@3px\", \"Mean GT Match Precision @ 3px\", \"float\"),\n",
    "    (\"median_gt_match_precision@3px\", \"Median GT Match Precision @ 3px\", \"float\"),\n",
    "    # Relative Pose Error (General)\n",
    "    (\"mrel_pose_error\", \"Mean Rel Pose Error\", \"float\"),\n",
    "    (\"median_rel_pose_error\", \"Median Rel Pose Error\", \"float\"),\n",
    "    (\"mransac_inl\", \"Mean RANSAC Inliers\", \"float\"),\n",
    "    (\"median_ransac_inl\", \"Median RANSAC Inliers\", \"float\"),\n",
    "    (\"mransac_inl%\", \"Mean RANSAC Inliers %\", \"float\"),\n",
    "    (\"median_ransac_inl%\", \"Median RANSAC Inliers %\", \"float\"),\n",
    "    # Relative Pose Error (Translation/Rotation)\n",
    "    (\"mrel_pose_t_error\", \"Mean Rel Pose Trans Error\", \"float\"),\n",
    "    (\"median_rel_pose_t_error\", \"Median Rel Pose Trans Error\", \"float\"),\n",
    "    (\"mrel_pose_r_error\", \"Mean Rel Pose Rot Error\", \"float\"),\n",
    "    (\"median_rel_pose_r_error\", \"Median Rel Pose Rot Error\", \"float\"),\n",
    "    (\"mrel_pose_t_error_rel\", \"Mean Rel Pose Trans Error (Rel)\", \"float\"),\n",
    "    (\"median_rel_pose_t_error_rel\", \"Median Rel Pose Trans Error (Rel)\", \"float\"),\n",
    "    (\"mrel_pose_r_error_rel\", \"Mean Rel Pose Rot Error (Rel)\", \"float\"),\n",
    "    (\"median_rel_pose_r_error_rel\", \"Median Rel Pose Rot Error (Rel)\", \"float\"),\n",
    "    # Relative Pose Error (Components)\n",
    "    (\"mrel_pose_t_error_x\", \"Mean Rel Pose Trans Error X\", \"float\"),\n",
    "    (\"median_rel_pose_t_error_x\", \"Median Rel Pose Trans Error X\", \"float\"),\n",
    "    (\"mrel_pose_t_error_y\", \"Mean Rel Pose Trans Error Y\", \"float\"),\n",
    "    (\"median_rel_pose_t_error_y\", \"Median Rel Pose Trans Error Y\", \"float\"),\n",
    "    (\"mrel_pose_t_error_z\", \"Mean Rel Pose Trans Error Z\", \"float\"),\n",
    "    (\"median_rel_pose_t_error_z\", \"Median Rel Pose Trans Error Z\", \"float\"),\n",
    "    (\"mrel_pose_r_error_roll\", \"Mean Rel Pose Rot Error Roll\", \"float\"),\n",
    "    (\"median_rel_pose_r_error_roll\", \"Median Rel Pose Rot Error Roll\", \"float\"),\n",
    "    (\"mrel_pose_r_error_pitch\", \"Mean Rel Pose Rot Error Pitch\", \"float\"),\n",
    "    (\"median_rel_pose_r_error_pitch\", \"Median Rel Pose Rot Error Pitch\", \"float\"),\n",
    "    (\"mrel_pose_r_error_yaw\", \"Mean Rel Pose Rot Error Yaw\", \"float\"),\n",
    "    (\"median_rel_pose_r_error_yaw\", \"Median Rel Pose Rot Error Yaw\", \"float\"),\n",
    "    # Absolute Localization Error\n",
    "    (\"mabs_loc_t_error\", \"Mean Abs Loc Trans Error\", \"float\"),\n",
    "    (\"median_abs_loc_t_error\", \"Median Abs Loc Trans Error\", \"float\"),\n",
    "    (\"mabs_loc_r_error\", \"Mean Abs Loc Rot Error\", \"float\"),\n",
    "    (\"median_abs_loc_r_error\", \"Median Abs Loc Rot Error\", \"float\"),\n",
    "    (\"mabs_loc_t_error_rel\", \"Mean Abs Loc Trans Error (Rel)\", \"float\"),\n",
    "    (\"median_abs_loc_t_error_rel\", \"Median Abs Loc Trans Error (Rel)\", \"float\"),\n",
    "    (\"mabs_loc_r_error_rel\", \"Mean Abs Loc Rot Error (Rel)\", \"float\"),\n",
    "    (\"median_abs_loc_r_error_rel\", \"Median Abs Loc Rot Error (Rel)\", \"float\"),\n",
    "    # Absolute Localization Error (Components)\n",
    "    (\"mabs_loc_t_error_x\", \"Mean Abs Loc Trans Error X\", \"float\"),\n",
    "    (\"median_abs_loc_t_error_x\", \"Median Abs Loc Trans Error X\", \"float\"),\n",
    "    (\"mabs_loc_t_error_y\", \"Mean Abs Loc Trans Error Y\", \"float\"),\n",
    "    (\"median_abs_loc_t_error_y\", \"Median Abs Loc Trans Error Y\", \"float\"),\n",
    "    (\"mabs_loc_t_error_z\", \"Mean Abs Loc Trans Error Z\", \"float\"),\n",
    "    (\"median_abs_loc_t_error_z\", \"Median Abs Loc Trans Error Z\", \"float\"),\n",
    "    (\"mabs_loc_r_error_roll\", \"Mean Abs Loc Rot Error Roll\", \"float\"),\n",
    "    (\"median_abs_loc_r_error_roll\", \"Median Abs Loc Rot Error Roll\", \"float\"),\n",
    "    (\"mabs_loc_r_error_pitch\", \"Mean Abs Loc Rot Error Pitch\", \"float\"),\n",
    "    (\"median_abs_loc_r_error_pitch\", \"Median Abs Loc Rot Error Pitch\", \"float\"),\n",
    "    (\"mabs_loc_r_error_yaw\", \"Mean Abs Loc Rot Error Yaw\", \"float\"),\n",
    "    (\"median_abs_loc_r_error_yaw\", \"Median Abs Loc Rot Error Yaw\", \"float\"),\n",
    "    # Absolute Localization Accuracy Thresholds\n",
    "    (\"mabs_loc_acc@0.25m_2deg\", \"Mean Abs Loc Acc @ 0.25m 2deg\", \"float\"),\n",
    "    (\"median_abs_loc_acc@0.25m_2deg\", \"Median Abs Loc Acc @ 0.25m 2deg\", \"float\"),\n",
    "    (\"mabs_loc_acc@0.5m_5deg\", \"Mean Abs Loc Acc @ 0.5m 5deg\", \"float\"),\n",
    "    (\"median_abs_loc_acc@0.5m_5deg\", \"Median Abs Loc Acc @ 0.5m 5deg\", \"float\"),\n",
    "    (\"mabs_loc_acc@1.0m_10deg\", \"Mean Abs Loc Acc @ 1.0m 10deg\", \"float\"),\n",
    "    (\"median_abs_loc_acc@1.0m_10deg\", \"Median Abs Loc Acc @ 1.0m 10deg\", \"float\"),\n",
    "    # Timing\n",
    "    (\"mextraction_time\", \"Mean Extraction Time\", \"float\"),\n",
    "    (\"median_extraction_time\", \"Median Extraction Time\", \"float\"),\n",
    "    (\"mmatching_time\", \"Mean Matching Time\", \"float\"),\n",
    "    (\"median_matching_time\", \"Median Matching Time\", \"float\"),\n",
    "    (\"mtotal_time\", \"Mean Total Time\", \"float\"),\n",
    "    (\"median_total_time\", \"Median Total Time\", \"float\"),\n",
    "    (\"extraction_fps\", \"Extraction FPS\", \"float\"),\n",
    "    (\"matching_fps\", \"Matching FPS\", \"float\"),\n",
    "    (\"total_fps\", \"Total FPS\", \"float\"),\n",
    "    # Pose AUC\n",
    "    (\"mpose_auc@5\", \"Mean Pose AUC @ 5 deg\", \"float\"),\n",
    "    (\"mpose_auc@10\", \"Mean Pose AUC @ 10 deg\", \"float\"),\n",
    "    (\"mpose_auc@20\", \"Mean Pose AUC @ 20 deg\", \"float\"),\n",
    "    # Metadata\n",
    "    (\"Model Type\", \"Model Type\", \"str\"),\n",
    "    (\"Model\", \"Model\", \"str\"),\n",
    "    (\"Method\", \"Method\", \"str\"),\n",
    "    (\"Dataset\", \"Dataset\", \"str\"),\n",
    "    (\"Step\", \"Step\", \"int\"),\n",
    "    (\"Labels\", \"Labels\", \"str\"),\n",
    "]\n",
    "\n",
    "import os\n",
    "\n",
    "# 1. Create the directory\n",
    "output_dir = \"./heatmaps\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not df_summary.empty:\n",
    "    unique_steps = sorted(df_summary[\"Step\"].unique())\n",
    "\n",
    "    # Metrics where lower values are better (Errors, Time)\n",
    "    lower_is_better_keywords = [\"error\", \"time\"]\n",
    "\n",
    "    for step in unique_steps:\n",
    "        subset_step = df_summary[df_summary[\"Step\"] == step]\n",
    "        if subset_step.empty:\n",
    "            continue\n",
    "\n",
    "        # Filter numeric metrics only\n",
    "        numeric_metrics = [m for m in summary_metrics if m[2] != \"str\"]\n",
    "\n",
    "        higher_better_metrics = []\n",
    "        lower_better_metrics = []\n",
    "\n",
    "        # Categorize metrics\n",
    "        for m in numeric_metrics:\n",
    "            col_name = m[0]\n",
    "            if col_name not in subset_step.columns:\n",
    "                continue\n",
    "\n",
    "            name_lower = col_name.lower()\n",
    "\n",
    "            # Logic: If 'error' or 'time' is present (and not 'fps'), use the error colormap\n",
    "            if (\n",
    "                any(k in name_lower for k in lower_is_better_keywords)\n",
    "                and \"fps\" not in name_lower\n",
    "            ):\n",
    "                lower_better_metrics.append(m)\n",
    "            else:\n",
    "                higher_better_metrics.append(m)\n",
    "\n",
    "        # Helper function to generate and save plots\n",
    "        def save_metric_group(metrics_list, cmap_name):\n",
    "            for metric, title, _ in metrics_list:\n",
    "                pivot_df = subset_step.pivot(\n",
    "                    index=\"Dataset\", columns=\"Model\", values=metric\n",
    "                )\n",
    "                if pivot_df.empty:\n",
    "                    continue\n",
    "\n",
    "                # Dynamic height based on number of rows\n",
    "                plt.figure(figsize=(10, len(pivot_df) * 0.8 + 2))\n",
    "\n",
    "                sns.heatmap(\n",
    "                    pivot_df, annot=True, fmt=\".3f\", cmap=cmap_name, linewidths=0.5\n",
    "                )\n",
    "                plt.title(f\"{title} ($\\Delta t={step})%\")\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Construct filename\n",
    "                # Clean filename to remove potentially problematic chars if necessary\n",
    "                safe_name = metric.replace(\"/\", \"_\")\n",
    "                filename = f\"{safe_name}_step_{step}.png\"\n",
    "                save_path = os.path.join(output_dir, filename)\n",
    "\n",
    "                plt.savefig(save_path, dpi=300)  # Save high res\n",
    "                plt.close()  # Close figure to free memory\n",
    "                print(f\"Saved: {save_path}\")\n",
    "\n",
    "        # 1. Save \"Higher is Better\" Metrics (Viridis: Yellow=High)\n",
    "        if higher_better_metrics:\n",
    "            save_metric_group(higher_better_metrics, \"viridis\")\n",
    "\n",
    "        # 2. Save \"Lower is Better\" Metrics (Magma: Yellow=High Error)\n",
    "        if lower_better_metrics:\n",
    "            save_metric_group(lower_better_metrics, \"magma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lupnt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
